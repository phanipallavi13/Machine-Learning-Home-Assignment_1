Name: Phani Pallavi Tallavajjhala

Student ID: 700766070

1 — Function Approximation by Hand

Dataset: (x,y)={(1,1),(2,2),(3,2),(4,5)}

Task:

1.	Try model θ=(1,0).Fill in predictions, residuals, squared residuals, and compute MSE.

2.	Try model θ=(0.5,1). Do the same.

3.	Which model fits better?

Dataset: (x,y) = {(1,1), (2,2), (3,2), (4,5)}

Model 1: θ = (1,0) → ŷ = θ1*x + θ2 = 1*x + 0 = x
x   y   ŷ   r=y-ŷ   r²
1   1   1    0      0
2   2   2    0      0
3   2   3   -1      1
4   5   4    1      1
MSE = (0+0+1+1)/4 = 0.5

Model 2: θ = (0.5,1) → ŷ = 0.5*x + 1
x   y   ŷ    r=y-ŷ   r²
1   1   1.5  -0.5    0.25
2   2   2.0   0      0
3   2   2.5  -0.5    0.25
4   5   3.0   2      4
MSE = (0.25+0+0.25+4)/4 = 1.125

Which fits better?
Model θ = (1,0) has lower MSE (0.5 vs 1.125), so it fits better.

2 — Random Guessing Practice

Cost function: J(θ_1, θ_2)=8〖(θ_1-0.3)〗^2+4〖(θ_2-0.7)〗^2

Task:

1. Compute J(0.1,0.2) and J(0.5,0.9).

2. Which guess is closer to the minimum (0.3,0.7)?

3. In 2–3 sentences, explain why random guessing is inefficient.

Compute:

•	J(0.1,0.2)=8(−0.2)2+4(−0.5)2=8(0.04)+4(0.25)=0.32+1=1.32

•	J(0.5,0.9)=8(0.2)2+4(0.2)2=8(0.04)+4(0.04)=0.32+0.16=0.48

Closer to the minimum (0.3,0.7): (0.5,0.9).

Why random guessing is inefficient:

Random selections hardly ever fall close to the optimum since the parameter space is wide and continuous.  Evaluations of settings that don't lower error are wasted in this way.  Gradient descent converges much more effectively by moving systematically toward lower cost using slope information.

3 — First Gradient Descent Iteration

Dataset: (1,3),(2,4),(3,6),(4,5)

Start: θ^(0)=(0,0), learning rate α=0.01.

Task:

	Compute predictions at θ^(0).

	Compute residuals and sums ∑r, ∑xr.

	Compute gradient ∇J.

	Update to θ^(1).

	Compute J(θ^(0)) and J(θ^(1)).

Continue from Homework 3 with θ^(1)

Task:

	Compute predictions at θ^(1).

	Compute residuals, ∑r, ∑xr .

	Compute gradient.

	Update to θ^((2)).

	Compare J(θ^(1)) and J(θ^(1)).

Dataset: (1,3), (2,4), (3,6), (4,5)
Start: θ^(0) = (b0, b1) = (0,0), learning rate α=0.01

Gradient formulas:
∂J/∂b1 = -(2/N) Σ x^(i)(y^(i) - ŷ^(i))
∂J/∂b0 = -(2/N) Σ (y^(i) - ŷ^(i))

---
Step A: Start at θ^(0) = (0,0)
Predictions: ŷ = [0, 0, 0, 0]
Residuals: r = [3, 4, 6, 5]
Σr = 18, Σ(xr) = 49

Gradient at θ^(0):
∂J/∂b0 = -(2/4)*18 = -9
∂J/∂b1 = -(2/4)*49 = -24.5
∇J(θ^(0)) = (-9, -24.5)

Update:
b0^(1) = 0 - 0.01(-9) = 0.09
b1^(1) = 0 - 0.01(-24.5) = 0.245
θ^(1) = (0.09, 0.245)

Costs:
J(θ^(0)) = (3^2 + 4^2 + 6^2 + 5^2)/4 = 21.5
J(θ^(1)) ≈ 15.256

---
Step B: Continue from θ^(1) = (0.09, 0.245)
Predictions: ŷ = [0.335, 0.58, 0.825, 1.07]
Residuals: r = [2.665, 3.42, 5.175, 3.93]
Σr = 15.19, Σ(xr) = 43.45

Gradient at θ^(1):
∂J/∂b0 = -(2/4)*15.19 = -7.595
∂J/∂b1 = -(2/4)*43.45 = -21.725

Update:
b0^(2) = 0.09 - 0.01(-7.595) = 0.16595
b1^(2) = 0.245 - 0.01(-21.725) = 0.46225
θ^(2) ≈ (0.16595, 0.46225)

Cost:
J(θ^(2)) ≈ 10.9 – 11.0 (depending on rounding)

---
Conclusion:
Cost decreases with each step:
J(θ^(0)) = 21.5 → J(θ^(1)) ≈ 15.26 → J(θ^(2)) ≈ 11.0
Gradient Descent is converging in the right direction.

4 — Compare Random Guessing vs Gradient Descent

(MSE: J = (1/N) Σ (y - (θ1 x + θ2))^2)

Dataset: (1,2), (2,2), (3,4), (4,6)

Random guess A: (θ1, θ2) = (0.2, 0.5)
J = 8.350000

Random guess B: (θ1, θ2) = (0.9, 0.1)
J = 1.935000

Gradient Descent (start at (0,0), α=0.01):
Σr = 14,  Σ(xr) = 42
dJ/dθ1 = -(2/N)Σ(x r) = -21.000000
dJ/dθ2 = -(2/N)Σ(r)   = -7.000000
After one step: (θ1, θ2) = (0.210000, 0.070000)
J after one step = 10.509150

Conclusion:
Lowest error here is Random guess B (0.9, 0.1). A single GD step from (0,0) hasn’t moved close enough yet;
continuing GD for more iterations will keep reducing J.

5 — Recognizing Underfitting and Overfitting

Imagine you train a model and notice the following results:

•	Training error is very high.

•	Test error is also very high.

Questions:

1.	Is this an example of underfitting or overfitting?

2.	Explain why this situation happens.

3.	Suggest two possible fixes.

Training error high, test error high → Underfitting.

Why: Model is too simple, under-trained, or features are inadequate; it can’t capture the signal.

Fixes (any two): Increase model capacity/features; reduce regularization; train longer; improve data quality/labels.

6 — Comparing Models

You test two different machine learning models on the same dataset:

•	Model A fits the training data almost perfectly but performs poorly on new unseen data.

•	Model B does not fit the training data very well and also performs poorly on unseen data.

Questions:

1.	Which model is overfitting? Which one is underfitting?

2.	In each case, what is the tradeoff between bias and variance?

3.	What would you recommend to improve each model?

Model A (near-perfect train, poor test) → Overfitting (low bias, high variance).

Improve: regularization (L2/L1), simplify architecture, collect more data/augmentation, early stopping, cross-validation.

Model B (poor train & test) → Underfitting (high bias, low variance).

Improve: add features, increase capacity, reduce regularization, train longer, tune learning rate.
